{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "include(\"HW4_leapfrog_student.jl\")\n",
      "include(\"HW4_leapfrog.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "test_leapfrog (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Want to test how the leapfrog integrator works"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_state = [1.,0.,0.,1.]; \n",
      "n_orbits = 5; \n",
      "n_steps = 200; \n",
      "duration = n_orbits*2*pi; \n",
      "dt = 0.01; \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@profile (for i in 1:15; integrate_leapfrog!(initial_state,dt,duration);end)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to profile integrate_leapfrog! First I will try and guess which parts of the function will take the most amount of time and what fraction of time they will take. Obviously one assumes that the most time will be spent in the computationally intensive parts. I would assume this would be in calculating the derivaties, specifically the accelerations because there are many steps involved (square roots, powers, etc). The obvious other part is the actual leapfrong step found in advance_leapfrog! I predict in total these two pieces of code will take up about 80% of the total computation time. The amount of time needed (in order of most to least) should be derivatives for the velocities, computation of the leap frog step, then coping the state to the log. The predict that the first operation will take about 48% of the total calculation and the second will take about 32%.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "leapfrog_profile_data = Profile.fetch(); \n",
      "fp = open(\"profile_data.txt\",\"w\"); \n",
      "Profile.print(fp,cols= 200);\n",
      "close(fp); "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@elapsed integrate_leapfrog!(initial_state,dt,duration)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "0.005344892"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "student_time = @elapsed integrate_leapfrog_student(initial_state,dt,duration);\n",
      "prof_time = @elapsed integrate_leapfrog!(initial_state,dt,duration);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All of the above code has been compilated in the file \"profiler.jl\". The profileing results that follow come from running that file. Interestingly, about 56% of the time spent by integrate_leapfrog! spent on line 95 which is where the new calculated state vector is copied to the log array. I calculated these percentages using different delay times for the profiler (0.001, 0.005, 0.0005, and 0.0008) to ensure there were no artifacts intoduced from the periodicity of the backtracing of the profiler. The time spent computing the new solution - which is called by the advance_leapfrog! method - only takes up about 35% of the time (which implicitly updates the derivaties). I predicted that advance_leapfrog! will take about 32% of the code, but this did not include the updating of the derivaties so I was pretty far off considering I predicted that both operations would take about 80% of the computational time. About 6.2% of the time was spent solely asserting that each array held by the log file was the same length as the state array. This is a little surprising to me because I thought the assert macro allowed the program to continue running while it checked its condition and rolled back the program if it was found to be false. \n",
      "\n",
      "I believe this code can be improved by eliminating the assert macro (since we generate the log array in the function there is a small chance of its length being incorrect). I will check in the following section whether any performance can be gained by changing the deepcopy command on line 95 of HW4_leapfrog.jl to just a copy command. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_state = Array(Float64,4); \n",
      "num_copies = 5000; \n",
      "copy_time = @elapsed (for i in 1:num_copies; copied_array = copy(test_state);end); \n",
      "deepcopy_time = @elapsed (for i in 1:num_copies; copied_array = deepcopy(test_state);end); \n",
      "deepcopy_time/copy_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "3.259668082913278"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appers that there is an increase in performance by a factor of 2-5 by changing deep copy to copy. There is no additional error introduced because all the elements of state are floating point numbers and there is no need for a deeper copy. Changing deepcopy to copy and removing the assert macro on line 94 of HW4_leapfrog.jl should produce an noticeable increase in performance. Somewhere between a factor of 1 and 4. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "include(\"optimized_HW4_leapfrog.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "optimized_integrate_leapfrog! (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_state = [1.,0.,0.,1.];\n",
      "prof_time = @elapsed(integrate_leapfrog!(initial_state,dt,duration))\n",
      "initial_state = [1.,0.,0.,1.]; \n",
      "optimized_prof_time = @elapsed(optimized_integrate_leapfrog!(initial_state,dt,duration))\n",
      "println(\"The increase in performance is \",prof_time/optimized_prof_time,\"x\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The increase in performance is 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".6391221375960574x\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ultimately it appears that the increase in performance is about 1.2-1.8 which is significant considering I simply removed one line of code (the  assert) and changed deepcopy to copy. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}