{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Problem 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "include(\"HW4_leapfrog_student.jl\")\n",
      "include(\"HW4_leapfrog.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Want to test how the leapfrog integrator works"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_state = [1.,0.,0.,1.]; \n",
      "n_orbits = 5; \n",
      "n_steps = 200; \n",
      "duration = n_orbits*2*pi; \n",
      "dt = 0.01; \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@profile (for i in 1:15; integrate_leapfrog!(initial_state,dt,duration);end)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We would like to profile integrate_leapfrog! First I will try and guess which parts of the function will take the most amount of time and what fraction of time they will take. Obviously one assumes that the most time will be spent in the computationally intensive parts. I would assume this would be in calculating the derivaties, specifically the accelerations because there are many steps involved (square roots, powers, etc). The obvious other part is the actual leapfrong step found in advance_leapfrog! I predict in total these two pieces of code will take up about 80% of the total computation time. The amount of time needed (in order of most to least) should be derivatives for the velocities, computation of the leap frog step, then coping the state to the log. The predict that the first operation will take about 48% of the total calculation and the second will take about 32%.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "leapfrog_profile_data = Profile.fetch(); \n",
      "fp = open(\"profile_data.txt\",\"w\"); \n",
      "Profile.print(fp,cols= 200);\n",
      "close(fp); "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@elapsed integrate_leapfrog!(initial_state,dt,duration)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "0.005344892"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "student_time = @elapsed integrate_leapfrog_student(initial_state,dt,duration);\n",
      "prof_time = @elapsed integrate_leapfrog!(initial_state,dt,duration);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All of the above code has been compilated in the file \"profiler.jl\". The profileing results that follow come from running that file. Interestingly, about 56% of the time spent by integrate_leapfrog! spent on line 95 which is where the new calculated state vector is copied to the log array. I calculated these percentages using different delay times for the profiler (0.001, 0.005, 0.0005, and 0.0008) to ensure there were no artifacts intoduced from the periodicity of the backtracing of the profiler. The time spent computing the new solution - which is called by the advance_leapfrog! method - only takes up about 35% of the time (which implicitly updates the derivaties). I predicted that advance_leapfrog! will take about 32% of the code, but this did not include the updating of the derivaties so I was pretty far off considering I predicted that both operations would take about 80% of the computational time. About 6.2% of the time was spent solely asserting that each array held by the log file was the same length as the state array. This is a little surprising to me because I thought the assert macro allowed the program to continue running while it checked its condition and rolled back the program if it was found to be false. \n",
      "\n",
      "I believe this code can be improved by eliminating the assert macro (since we generate the log array in the function there is a small chance of its length being incorrect). I will check in the following section whether any performance can be gained by changing the deepcopy command on line 95 of HW4_leapfrog.jl to just a copy command. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_state = Array(Float64,4); \n",
      "num_copies = 5000; \n",
      "copy_time = @elapsed (for i in 1:num_copies; copied_array = copy(test_state);end); \n",
      "deepcopy_time = @elapsed (for i in 1:num_copies; copied_array = deepcopy(test_state);end); \n",
      "deepcopy_time/copy_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "3.259668082913278"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appers that there is an increase in performance by a factor of 2-5 by changing deep copy to copy. There is no additional error introduced because all the elements of state are floating point numbers and there is no need for a deeper copy. Changing deepcopy to copy and removing the assert macro on line 94 of HW4_leapfrog.jl should produce an noticeable increase in performance. Somewhere between a factor of 1 and 4. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "include(\"optimized_HW4_leapfrog.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "optimized_integrate_leapfrog! (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_state = [1.,0.,0.,1.];\n",
      "prof_time = @elapsed(integrate_leapfrog!(initial_state,dt,duration))\n",
      "initial_state = [1.,0.,0.,1.]; \n",
      "optimized_prof_time = @elapsed(optimized_integrate_leapfrog!(initial_state,dt,duration))\n",
      "println(\"The increase in performance is \",prof_time/optimized_prof_time,\"x\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The increase in performance is 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".6391221375960574x\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ultimately it appears that the increase in performance is about 1.2-1.8 which is significant considering I simply removed one line of code (the  assert) and changed deepcopy to copy. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is the breakdown before and after the optimization. HW4_leapfrog.jl: 56.2% spent on line 95 which involved a deepcopy of the state to the long, 32.7% on line 87 which advanced the leapfrog step (did the actual calculation), 7.7% was spent on line 94 which asserted that the size of the log array was the same as the state array. \n",
      "\n",
      "After the optimization which eliminated the assert on line 94 and changed the deepcopy to a copy on line 95, we have the new function in the file optimized_HW4_leapfrog.jl: 78.4% on line 31 for advancing the leapfrog, 19.4% spent copying the data from the state array to the log, and 1.6% spent checking whether the data should be added to the log or skipped. \n",
      "\n",
      "Interestingly, sometimes it appears that sometimes the optimized function runs SLOWER than the original fucntion which is strange. But in general its 1.2-1.8 times faster. I believe that it is good that more than 3/4 of the calculation is spent doing the actual calculation and not in memory management. The advance leapfrog function can be further optimized while memory management functions cannot be changed significantly.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Problem 2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function f(x::Float64)\n",
      "    return exp(-0.5*x^2)/sqrt(2*pi)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "f (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#returns the integral of an input function from a to b \n",
      "#inputs:\n",
      "#f   - fucntion to be integrated \n",
      "#a   - begining point of integral (Float64)\n",
      "#b   - ending point of integral  (Float64)\n",
      "#N   - number of integration steps (Int)\n",
      "function for_integrate(fn, a::Float64, b::Float64, N = 100)\n",
      "    dx = (b-a)/N; \n",
      "    my_sum = 0.5*fn(a); \n",
      "    for i in 1:N-1\n",
      "        x = a+i*dx;\n",
      "        my_sum += fn(x);\n",
      "    end\n",
      "    my_sum += 0.5*fn(b)\n",
      "    my_sum *= dx;\n",
      "    \n",
      "    return my_sum; \n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "for_integrate (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = 1.0; \n",
      "my_int = for_integrate(f,-a,a,100);\n",
      "real_int = erf(a/sqrt(2)); \n",
      "error = (my_int-real_int)/real_int"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "-2.3629478571796172e-5"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "to test the integrator note that $\\int_{-a}^a e^{-x^2/2}dx = erf(a/\\sqrt{2})$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 100; \n",
      "for_time_4 = @elapsed (for j in 1:n for_integrate(f,-1.,1.,10000); end;)\n",
      "for_time_4 /= n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "0.00138572127"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for_time_8 = @elapsed for_integrate(f,-1.,1.,100000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "11.419328427"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function map_and_reduce(fn, a, b, N = 1000)\n",
      "    dx = (b-a)/N; \n",
      "    x = [a+i*dx for i in 0:N];\n",
      "    mapped = map(f,x); \n",
      "    my_sum = reduce(+,mapped); \n",
      "    my_sum = my_sum - 0.5*mapped[1] - 0.5*mapped[N+1]; \n",
      "    my_sum *= dx\n",
      "    return my_sum; \n",
      "end "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "map_and_reduce (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for_time_4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "0.00138572127"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for_time_8"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "11.419328427"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = linspace(0,1); \n",
      "y = linspace(1,2); \n",
      "@devec x+y; "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LoadError",
       "evalue": "@devec not defined\nat In[0]:3",
       "output_type": "pyerr",
       "traceback": [
        "@devec not defined\nat In[0]:3"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = -1.0; \n",
      "b = 1.0; \n",
      "N = 1000; \n",
      "dx = (b-a)/N; \n",
      "x = [a+i*dx for i in 1:N-1];\n",
      "#my_sum += exp(-0.5.*x.^)./sqrt(2*pi);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "-1.0"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}